{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/fashion/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from itertools import chain\n",
    "from math import ceil\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras import losses\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top = False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(base_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count=227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(4096, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(label_count, activation = 'sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/fashion/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "head_model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model.load_weights('results/best_weights_2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 227)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd loop attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39706 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "gen_test = ImageDataGenerator().flow_from_directory('images_test',\n",
    "                                                    target_size=(224, 224),\n",
    "                                                    class_mode=None, \n",
    "                                                    shuffle=False,\n",
    "                                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39706"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_images_test = len(gen_test.filenames)\n",
    "num_images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39706,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ids_test_all = np.array([int(fn[5:-4]) for fn in gen_test.filenames])\n",
    "img_ids_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 1241\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "chunked_predictions = []\n",
    "#chunked_img_ids = []\n",
    "\n",
    "print(f'Batches: {ceil(num_images_test / gen_test.batch_size)}')\n",
    "for i in range(ceil(num_images_test / gen_test.batch_size)):\n",
    "    if i // 10 == i / 10:\n",
    "        print(i)\n",
    "    batch = gen_test.next()\n",
    "    predictions = head_model.predict(batch)\n",
    "    del batch\n",
    "    chunked_predictions.append(predictions)\n",
    "    # if i >= 10:\n",
    "    #     print('breaking')\n",
    "    #     break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(chunked_predictions).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(chunked_img_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([pd.DataFrame(pred) for pred in chunked_predictions])\n",
    "combined.index = img_ids_test_all[:len(combined.index)]\n",
    "combined.columns = range(1, 1 + len(combined.columns))\n",
    "combined.sort_index(inplace=True)\n",
    "combined.head()\n",
    "combined.to_csv('results/combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process combined df into submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process(row):\n",
    "#     qualified_labels = []\n",
    "#     for i in row.index:\n",
    "#         # combined.iloc[2].sort_values(ascending=False)\n",
    "#         if row[i] > 0.5:\n",
    "#             qualified_labels.append(i)\n",
    "    \n",
    "#     # if nothing qualified, use the label with max proba\n",
    "#     if len(qualified_labels) == 0:\n",
    "#         qualified_labels.append(row.idxmax())\n",
    "        \n",
    "#     return qualified_labels\n",
    "\n",
    "# processed = combined.apply(process, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    qualified_labels = []\n",
    "    for i in row.sort_values(ascending=False).index:  # in case sorting matters\n",
    "        if row[i] > 0.5:\n",
    "            qualified_labels.append(i)\n",
    "    \n",
    "    # if nothing qualified, use the label with max proba\n",
    "    if len(qualified_labels) == 0:\n",
    "        qualified_labels.append(row.idxmax())\n",
    "    \n",
    "    return ' '.join(str(label) for label in qualified_labels)\n",
    "\n",
    "processed = pd.DataFrame(combined.apply(process, axis=1))\n",
    "processed.index.name = 'image_id'\n",
    "processed.columns = 'label_id', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.to_csv('results/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:fashion]",
   "language": "python",
   "name": "conda-env-fashion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
